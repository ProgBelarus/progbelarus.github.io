<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Georgy Noarov</title> <meta name="author" content="Georgy Noarov"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://progbelarus.github.io/publications/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Georgy </span>Noarov</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <p>Below is a list of my journal and conference publications and preprints in reverse chronological order. You can also check out my <a href="https://scholar.google.com/citations?hl=en&amp;user=P0-hDecAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar profile</a>.</p> <div class="publications"> <h2 class="year">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div id="noarov2025foundations" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">Foundations of Top-\(k\) Decoding For Language Models</div> <div class="author"> <em>Georgy Noarov</em>, Soham Mallick, Tao Wang, Sunay Joshi, Yan Sun, Yangxinyu Xie, Mengxin Yu, and Edgar Dobriban</div> <div class="periodical"> <em>Manuscript</em> 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2505.19371" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> </div> <div class="abstract hidden"> <p>Top-\(k\) decoding is a widely used method for sampling from LLMs: at each token, only the largest \(k\) next-token probabilities are kept, and the next token is sampled after re-normalizing them to sum to unity. Top-\(k\) and other sampling methods are motivated by the intuition that true next-token distributions are sparse, and the noisy LLM probabilities need to be truncated. However, to our knowledge, a precise theoretical motivation for the use of top-\(k\) decoding is missing. In this work, we develop a theoretical framework that both explains and generalizes top-\(k\) decoding. We view decoding at a fixed token as the recovery of a sparse probability distribution. We consider Bregman decoders obtained by minimizing a separable Bregman divergence (for both the primal and dual cases) with a sparsity-inducing \(\ell_0\)-regularization. Despite the combinatorial nature of the objective, we show how to optimize it efficiently for a large class of divergences. We show that the optimal decoding strategies are greedy, and further that the loss function is discretely convex in \(k\), so that binary search provably and efficiently finds the optimal \(k\). We show that top-\(k\) decoding arises as a special case for the KL divergence, and identify new decoding strategies that have distinct behaviors (e.g., non-linearly up-weighting larger probabilities after re-normalization).</p> </div> </div> </div> </li> <li> <div class="row"> <div id="noarov2025stronger" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">Stronger Neyman Regret Guarantees for Adaptive Experimental Design</div> <div class="author"> <em>Georgy Noarov</em>, Riccardo Fogliato, Martin Bertran, and Aaron Roth</div> <div class="periodical"> <em>42nd International Conference on Machine Learning (ICML)</em> 2025 </div> <div class="prize" color="var(--global-pubs-bg-color);"> <b>Selected as a Spotlight Presentation</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2502.17427" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://github.com/amazon-science/adaptive-abtester" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>We study the design of adaptive, sequential experiments for unbiased average treatment effect (ATE) estimation in the design-based potential outcomes setting. Our goal is to develop adaptive designs offering <i> sublinear Neyman regret </i>, meaning their efficiency must approach that of the hindsight-optimal nonadaptive design. Recent work of Dai et al. [2023] introduced ClipOGD, the first method achieving \(\widetilde{O}(\sqrt{T})\) expected Neyman regret under mild conditions. In this work, we propose adaptive designs with substantially stronger Neyman regret guarantees. In particular, we modify ClipOGD to obtain anytime \(\widetilde{O}(\log T)\) Neyman regret under natural boundedness assumptions. Further, in the setting where experimental units have pre-treatment covariates, we introduce and study a class of contextual ``multigroup'' Neyman regret guarantees: Given any set of possibly overlapping groups based on the covariates, the adaptive design outperforms each group's best non-adaptive designs. In particular, we develop a contextual adaptive design with \(\widetilde{O}(\sqrt{T})\) anytime multigroup Neyman regret. We empirically validate the proposed designs through an array of experiments.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="noarov2023high" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">High-Dimensional Prediction for Sequential Decision Making</div> <div class="author"> <em>Georgy Noarov</em>, Ramya Ramalingam, Aaron Roth, and Stephan Xie</div> <div class="periodical"> <em>42nd International Conference on Machine Learning (ICML)</em> 2025 </div> <div class="prize" color="var(--global-pubs-bg-color);"> <b>Selected as a Spotlight Presentation</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2310.17651" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>We give an efficient algorithm for producing multi-dimensional forecasts in an online adversarial environment that have low bias subject to any polynomial number of conditioning events, that can depend both on external context and on our predictions themselves. We demonstrate the use of this algorithm with several applications. We show how to make predictions that can be transparently consumed by any polynomial number of downstream decision makers with different utility functions, guaranteeing them diminishing swap regret at optimal rates. We also give the first efficient algorithms for guaranteeing diminishing conditional regret in online combinatorial optimization problems for an arbitrary polynomial number of conditioning events -- i.e. on an arbitrary number of intersecting subsequences determined both by context and our own predictions. Finally, we give the first efficient algorithm for online multicalibration with \(O(T^{2/3})\) rates in the ECE metric.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">noarov2023high</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{High-Dimensional Prediction for Sequential Decision Making}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Noarov, Georgy and Ramalingam, Ramya and Roth, Aaron and Xie, Stephan}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2310.17651}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{42nd International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">prize</span> <span class="p">=</span> <span class="s">{Selected as a Spotlight Presentation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div id="Noarov2023ScopeMC" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">The Scope of Multicalibration: Characterizing Multicalibration via Property Elicitation</div> <div class="author"> <em>Georgy Noarov</em>, and Aaron Roth</div> <div class="periodical"> <em>40th International Conference on Machine Learning (ICML)</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2302.08507" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>We make a connection between multicalibration and property elicitation and show that (under mild technical conditions) it is possible to produce a multicalibrated predictor for a continuous scalar distributional property \(\Gamma\) if and only if \(\Gamma\) is elicitable. On the negative side, we show that for non-elicitable continuous properties there exist simple data distributions on which even the true distributional predictor is not calibrated. On the positive side, for elicitable \(\Gamma\), we give simple canonical algorithms for the batch and the online adversarial setting, that learn a \(\Gamma\)-multicalibrated predictor. This generalizes past work on multicalibrated means and quantiles, and in fact strengthens existing online quantile multicalibration results. To further counter-weigh our negative result, we show that if a property \(\Gamma_1\) is not elicitable by itself, but is elicitable conditionally on another elicitable property \(\Gamma_0\), then there is a canonical algorithm that jointly multicalibrates \(\Gamma_1\) and \(\Gamma_0\); this generalizes past work on mean-moment multicalibration. Finally, as applications of our theory, we provide novel algorithmic and impossibility results for fair (multicalibrated) risk assessment.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Noarov2023ScopeMC</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Scope of Multicalibration: Characterizing Multicalibration via Property Elicitation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Noarov, Georgy and Roth, Aaron}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2302.08507}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{40th International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="Jung2022BatchMC" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">Batch Multivalid Conformal Prediction</div> <div class="author"> Christopher Jung, <em>Georgy Noarov</em>, Ramya Ramalingam, and Aaron Roth</div> <div class="periodical"> <em>11th International Conference on Learning Representations (ICLR)</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2209.15145" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/ProgBelarus/BatchMultivalidConformal" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>We develop fast distribution-free conformal prediction algorithms for obtaining multivalid coverage on exchangeable data in the batch setting. Multivalid coverage guarantees are stronger than marginal coverage guarantees in two ways: (1) They hold even conditional on group membership -- that is, the target coverage level \(1-\alpha\) holds conditionally on membership in each of an arbitrary (potentially intersecting) group in a finite collection \(G\) of regions in the feature space. (2) They hold even conditional on the value of the threshold used to produce the prediction set on a given example. In fact multivalid coverage guarantees hold even when conditioning on group membership and threshold value simultaneously. We give two algorithms: both take as input an arbitrary non-conformity score and an arbitrary collection of possibly intersecting groups \(G\), and then can equip arbitrary black-box predictors with prediction sets. Our first algorithm (BatchGCP) is a direct extension of quantile regression, needs to solve only a single convex minimization problem, and produces an estimator which has group-conditional guarantees for each group in \(G\). Our second algorithm (BatchMVP) is iterative, and gives the full guarantees of multivalid conformal prediction: prediction sets that are valid conditionally both on group membership and non-conformity threshold. We evaluate the performance of both of our algorithms in an extensive set of experiments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Jung2022BatchMC</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Batch Multivalid Conformal Prediction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jung, Christopher and Noarov, Georgy and Ramalingam, Ramya and Roth, Aaron}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2209.15145}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{11th International Conference on Learning Representations (ICLR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/ProgBelarus/BatchMultivalidConformal}</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{conformal.png}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div id="Bastani2022PracticalAM" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">Practical Adversarial Multivalid Conformal Prediction</div> <div class="author"> Osbert Bastani, Varun Gupta, Christopher Jung, <em>Georgy Noarov</em>, Ramya Ramalingam, and Aaron Roth</div> <div class="periodical"> <em>36th Conference on Neural Information Processing Systems (NeurIPS)</em> 2022 </div> <div class="prize" color="var(--global-pubs-bg-color);"> <b>Selected as an Oral Presentation</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2206.01067" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/ProgBelarus/MultiValidPrediction" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/MVP_Slides_Conf.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> <a href="https://slideslive.com/38991952" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Talk Video</a> </div> <div class="abstract hidden"> <p>We give a simple, generic conformal prediction method for sequential prediction that achieves target empirical coverage guarantees against adversarially chosen data. It is computationally lightweight -- comparable to split conformal prediction -- but does not require having a held-out validation set, and so all data can be used for training models from which to derive a conformal score. It gives stronger than marginal coverage guarantees in two ways. First, it gives threshold calibrated prediction sets that have correct empirical coverage even conditional on the threshold used to form the prediction set from the conformal score. Second, the user can specify an arbitrary collection of subsets of the feature space -- possibly intersecting -- and the coverage guarantees also hold conditional on membership in each of these subsets. We call our algorithm MVP, short for MultiValid Prediction. We give both theory and an extensive set of empirical evaluations.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Bastani2022PracticalAM</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Practical Adversarial Multivalid Conformal Prediction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bastani, Osbert and Gupta, Varun and Jung, Christopher and Noarov, Georgy and Ramalingam, Ramya and Roth, Aaron}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://slideslive.com/38991952}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2206.01067}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{36th Conference on Neural Information Processing Systems (NeurIPS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/ProgBelarus/MultiValidPrediction}</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{conformal.png}</span><span class="p">,</span>
  <span class="na">slides</span> <span class="p">=</span> <span class="s">{MVP_Slides_Conf.pdf}</span><span class="p">,</span>
  <span class="na">prize</span> <span class="p">=</span> <span class="s">{Selected as an Oral Presentation}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="Noarov2021OnlineMM" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">Online Minimax Multiobjective Optimization: Multicalibeating and Other Applications</div> <div class="author"> Daniel Lee, <em>Georgy Noarov</em>, Mallesh M. Pai, and Aaron Roth</div> <div class="periodical"> <em>36th Conference on Neural Information Processing Systems (NeurIPS)</em> 2022 </div> <div class="prize" color="var(--global-pubs-bg-color);"> <b>Selected as an Oral Presentation</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2108.03837" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.youtube.com/watch?v=ZiB5Y88SawA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Talk Video</a> </div> <div class="abstract hidden"> <p>We introduce a simple but general online learning framework, in which at every round, an adaptive adversary introduces a new game, consisting of an action space for the learner, an action space for the adversary, and a vector valued objective function that is convex-concave in every coordinate. The learner and the adversary then play in this game. The learner's goal is to play so as to minimize the maximum coordinate of the cumulative vector-valued loss. The resulting one-shot game is not convex-concave, and so the minimax theorem does not apply. Nevertheless, we give a simple algorithm that can compete with the setting in which the adversary must announce their action first, with optimally diminishing regret. We demonstrate the power of our simple framework by using it to derive optimal bounds and algorithms across a variety of domains. This includes no regret learning: we can recover optimal algorithms and bounds for minimizing external regret, internal regret, adaptive regret, multigroup regret, subsequence regret, and a notion of regret in the sleeping experts setting. Next, we use it to derive a variant of Blackwell's Approachability Theorem, which we term "Fast Polytope Approachability". Finally, we are able to recover recently derived algorithms and bounds for online adversarial multicalibration and related notions (mean-conditioned moment multicalibration, and prediction interval multivalidity).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Noarov2021OnlineMM</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{multiobjective.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=ZiB5Y88SawA}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Online Minimax Multiobjective Optimization: Multicalibeating and Other Applications}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lee, Daniel and Noarov, Georgy and Pai, Mallesh M. and Roth, Aaron}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{36th Conference on Neural Information Processing Systems (NeurIPS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2108.03837}</span><span class="p">,</span>
  <span class="na">prize</span> <span class="p">=</span> <span class="s">{Selected as an Oral Presentation}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="Gupta2022OnlineML" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">Online Multivalid Learning: Means, Moments, and Prediction Intervals</div> <div class="author"> Varun Gupta, Christopher Jung, <em>Georgy Noarov</em>, Mallesh M. Pai, and Aaron Roth</div> <div class="periodical"> <em>13th Conference on Innovations in Theoretical Computer Science (ITCS)</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2101.01739" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.youtube.com/watch?v=ceCm3GCOVqU" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Talk Video</a> </div> <div class="abstract hidden"> <p>We present a general, efficient technique for providing contextual predictions that are ``multivalid'' in various senses, against an online sequence of adversarially chosen examples \( (x,y)\). This means that the resulting estimates correctly predict various statistics of the labels y not just marginally -- as averaged over the sequence of examples -- but also conditionally on \(x \in g\) for any \(g\) belonging to an arbitrary intersecting collection of groups \(G\). We provide three instantiations of this framework. The first is mean prediction, which corresponds to an online algorithm satisfying the notion of multicalibration from Hebert-Johnson et al. The second is variance and higher moment prediction, which corresponds to an online algorithm satisfying the notion of mean-conditioned moment multicalibration from Jung et al. [2021] Finally, we define a new notion of prediction interval multivalidity, and give an algorithm for finding prediction intervals which satisfy it. Because our algorithms handle adversarially chosen examples, they can equally well be used to predict statistics of the residuals of arbitrary point prediction methods, giving rise to very general techniques for quantifying the uncertainty of predictions of black box algorithms, even in an online adversarial setting. When instantiated for prediction intervals, this solves a similar problem as conformal prediction, but in an adversarial environment and with multivalidity guarantees stronger than simple marginal coverage guarantees.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Gupta2022OnlineML</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{multiobjective.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Online Multivalid Learning: Means, Moments, and Prediction Intervals}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gupta, Varun and Jung, Christopher and Noarov, Georgy and Pai, Mallesh M. and Roth, Aaron}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2101.01739}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=ceCm3GCOVqU}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{13th Conference on Innovations in Theoretical Computer Science (ITCS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div id="doi:10.1287/moor.2021.1144" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">Computing Approximate Equilibria in Weighted Congestion Games via Best-Responses</div> <div class="author"> Yiannis Giannakopoulos, <em>Georgy Noarov</em>, and Andreas S. Schulz</div> <div class="periodical"> <em>Mathematics of Operations Research</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/1810.12806" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://pubsonline.informs.org/doi/abs/10.1287/moor.2021.1144" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p> We present a deterministic polynomial-time algorithm for computing \( d^{d+o(d)} \)-approximate (pure) Nash equilibria in weighted congestion games with polynomial cost functions of degree at most \(d\). This is an exponential improvement of the approximation factor relative to the previously best deterministic algorithm. An appealing additional feature of the algorithm is that it only uses best-improvement steps in the actual game, as opposed to the previously best algorithms, that first had to transform the game itself. Our algorithm is an adaptation of the seminal algorithm by Caragiannis at al. [2011, 2015], but we utilize an approximate potential function directly on the original game instead of an exact one on a modified game. A critical component of our analysis, which is of independent interest, is the derivation of a novel bound of \( [d/W(d/\rho)]^{d+1} \) for the price of anarchy (PoA) of \( \rho \)-approximate equilibria in weighted congestion games, where \(W\) is the Lambert-W function. More specifically, we show that this PoA is exactly equal to \(\Phi_{d,\rho}^{d+1} \), where \( \Phi_{d,\rho} \) is the unique positive solution of the equation \( \rho (x+1)^d = x^{d+1} \). Our upper bound is derived via a smoothness-like argument, and thus holds even for mixed Nash and correlated equilibria, whereas our lower bound is simple enough to apply even to singleton congestion games.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">doi:10.1287/moor.2021.1144</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{congestion.jpg}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Congestion Games}</span><span class="p">,</span>
  <span class="na">show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Giannakopoulos, Yiannis and Noarov, Georgy and Schulz, Andreas S.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Computing Approximate Equilibria in Weighted Congestion Games via Best-Responses}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{1810.12806}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Mathematics of Operations Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{47}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{643-664}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1287/moor.2021.1144}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1287/moor.2021.1144}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1287/moor.2021.1144}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://pubsonline.informs.org/doi/abs/10.1287/moor.2021.1144}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <ol class="bibliography"><li> <div class="row"> <div id="Neyman2021BinarySR" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">Binary Scoring Rules that Incentivize Precision</div> <div class="author"> Eric Neyman, <em>Georgy Noarov</em>, and S. Matthew Weinberg</div> <div class="periodical"> <em>22nd ACM Conference on Economics and Computation (EC)</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2002.10669" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/EC_Poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>All proper scoring rules incentivize an expert to predict <i> accurately </i> (report their true estimate), but not all proper scoring rules equally incentivize <i> precision. </i> Rather than treating the expert's belief as exogenously given, we consider a model where a rational expert can endogenously refine their belief by repeatedly paying a fixed cost, and is incentivized to do so by a proper scoring rule. Specifically, our expert aims to predict the probability that a biased coin flipped tomorrow will land heads, and can flip the coin any number of times today at a cost of \(c\) per flip. Our first main result defines an <i> incentivization index </i> for proper scoring rules, and proves that this index measures the expected error of the expert's estimate (where the number of flips today is chosen adaptively to maximize the predictor's expected payoff). Our second main result finds the unique scoring rule which optimizes the incentivization index over all proper scoring rules. We also consider extensions to minimizing the \(\ell\)th moment of error, and again provide an incentivization index and optimal proper scoring rule. In some cases, the resulting scoring rule is differentiable, but not infinitely differentiable. In these cases, we further prove that the optimum can be uniformly approximated by polynomial scoring rules. Finally, we compare common scoring rules via our measure, and include simulations confirming the relevance of our measure even in domains outside where it provably applies.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Neyman2021BinarySR</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{incentives.jpg}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Binary Scoring Rules that Incentivize Precision}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Neyman, Eric and Noarov, Georgy and Weinberg, S. Matthew}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2002.10669}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{22nd ACM Conference on Economics and Computation (EC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">poster</span> <span class="p">=</span> <span class="s">{EC_Poster.pdf}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2019</h2> <ol class="bibliography"><li> <div class="row"> <div id="Guerzhoy2019AIEM" class="col-sm-12"> <div class="title" style="background-color:rgb(218,230,255);">AI Education Matters: Building a Fake News Detector</div> <div class="author"> Michael Guerzhoy, Lisa Zhang, and <em>Georgy Noarov</em> </div> <div class="periodical"> <em>AI Matters</em> 2019 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/10.1145/3362077.3362082" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="http://sigai.acm.org/static/aimatters/5-3/AIMatters-5-3-05-Guerzhoy.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Guerzhoy2019AIEM</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{fakenews.avif}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AI Education Matters: Building a Fake News Detector}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guerzhoy, Michael and Zhang, Lisa and Noarov, Georgy}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{AI Matters}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{18-20}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{http://sigai.acm.org/static/aimatters/5-3/AIMatters-5-3-05-Guerzhoy.pdf}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/10.1145/3362077.3362082}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Georgy Noarov. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>